{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The purpose of the following document is to incorporate and promote the use of SAGE, an open-source math programming language, as a tool for both educational and research purposes. To that end, we make some contributions to the development of SAGE's algebra packages by doing the following:\n",
    "\n",
    "1. Defining standard representations of diagram algebras as they act on self-tensored vector spaces\n",
    "2. Designing and implementing an algorithm to calculate the central, primitive, orthogonal idempotents of the Brauer Algebra\n",
    "3. Exploring the various ways that the idempotents may help us in understanding how modules decompose into direct sums of isotypic components of the underlying algebras\n",
    "\n",
    "This document is in reality an interactive one. While the following printout could simply be read, we encourage the reader to follow along by downloading the jupyter notebook file (.ipynb format), and opening it after downloading SAGE (http://www.sagemath.org/).\n",
    "\n",
    "Before proceeding any further, we would need to define many of the important objects that we will be studying.\n",
    "\n",
    "## Basic Definitions\n",
    "\n",
    "We say that the set $A$ is a unital algebra if $(A,+,\\cdot)$ is a ring with unity for which $(A,+)$ is a vector space over a field $F$, and\n",
    "\n",
    "$$\\alpha(a\\cdot b)=(\\alpha a)\\cdot b=a\\cdot(\\alpha b)$$\n",
    "\n",
    "for all $a,b\\in A$ and $\\alpha\\in F$. If G is a group, then the set $FG=\\text{span}_F\\{g~:~g\\in G\\}$ that is the $F$-linear span of the elements of $G$ and has a canonical unital algebra structure we refer to as the group algebra. For example if $G=S_2=\\{\\text{id},(1~2) \\}$ is the symmetric group acting on 2 elements, addition is defined as $(\\alpha_1,\\alpha_2)+(\\beta_1,\\beta_2)=(\\alpha_1\\text{id}+\\alpha_2 (1~2))+(\\beta_1\\text{id}+\\beta_2 (1~2))=((\\alpha_1+\\beta_1)\\text{id}+(\\alpha_2,\\beta_2) (1~2))=(\\alpha_1+\\beta_1,\\alpha_2+\\beta_2)$. As for multiplication,\n",
    "\n",
    "$$(\\alpha_1,\\alpha_2)\\cdot(\\beta_1,\\beta_2)=(\\alpha_1\\text{id}+\\alpha_2 (1~2))\\cdot(\\beta_1\\text{id}+\\beta_2 (1~2))=\\alpha_1\\beta_1 \\text{id}^2+\\alpha_1\\beta_2 \\text{id}(1~2)+\\alpha_2\\beta_1 (1~2)\\text{id}+\\alpha_2\\beta_2 (1~2)^2=(\\alpha_1\\beta_1+\\alpha_2\\beta_2,\\alpha_1\\beta_2+\\alpha_2\\beta_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $R$ is a ring, we say an abelian group $(M,+)$ is a left $R$-module if there is a left action $R\\times M\\rightarrow M$ $(m\\mapsto r\\cdot m)$ satisfying:\n",
    "\n",
    "1. $1_R\\cdot m=m$ for all $m\\in M$(Identity-Preserving)\n",
    "2. $a(b\\cdot m)=(ab)\\cdot m$ for all $a,b\\in R$, $m\\in M$ (Associative Action)\n",
    "3. $(a+b)\\cdot m=a\\cdot m + b\\cdot m$ for all $a,b\\in R$, $m\\in M$ (Right-Distributive over $R$-addition)\n",
    "4. $a\\cdot(m+n)=a\\cdot m+b\\cdot n$ for all $a\\in R$, $m,n\\in M$ (Left-Distributive over $M$-addition)\n",
    "\n",
    "If $M$ is a vector space over a field $F$, then we also require that\n",
    "5. $a\\cdot (\\alpha m+\\beta n)=\\alpha a\\cdot m+\\beta a\\cdot n$ (Left-Distributive and $F$-linear over $M$-addition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $A$ is a unital ring, we would define a left $A$-module the exact same way. Let $B$ be another unital algebra.\n",
    "\n",
    "We say $M$ is a right $B$ module if instead acting by $B$ happened on the right: $m\\cdot b \\in M$.\n",
    "\n",
    "1. $m\\cdot 1_B=m$ for all $m\\in M$(Identity-Preserving)\n",
    "2. $(m\\cdot a)\\cdot b= m\\cdot (ab)$ for all $a,b\\in B$, $m\\in M$ (Associative Action)\n",
    "3. $m\\cdot (a+b)=m\\cdot a + m\\cdot b$ for all $a,b\\in B$, $m\\in M$ (Left-Distributive over $R$-addition)\n",
    "4. $(m+n)\\cdot a=m\\cdot a+n\\cdot a$ for all $a\\in R$, $m,n\\in M$ (Right-Distributive over $M$-addition)\n",
    "\n",
    "We say that $M$ is an (A,B) bimodule if:\n",
    "\n",
    "1. $M$ is a left $A$ module and a right $B$ module\n",
    "2. $a(mb)=(am)b$ for all $a\\in A,b\\in B, m\\in M$\n",
    "\n",
    "Sometimes we call $M$ an $A\\otimes B$ left module if $A\\otimes B$ has a left action of the form $a\\otimes b \\cdot m=a(mb)=(am)b$. But this only makes sense when the actions of $A$ and $B$ commute with one another, as it wouldn't matter what action would be applied first. \n",
    "\n",
    "## Ideals, Semisimplicity, and Decompositions\n",
    "\n",
    "We say that $Q\\subset R$ is a left ideal if $rq\\in Q$ for all $r\\in R$ and $q\\in Q$, and $Q$ is an abelian group with addition is restricted to $Q$. $Q$ is a right ideal if instead $qr\\in Q$.\n",
    "\n",
    "Let $M,N$ be $R$ modules. We say $N\\subset M$ is a submodule if $a\\cdot n\\in N$ for all $a\\in R$ and $(N,+)$ is an abelian group. All rings and algebras, $R$ are natural left $R$ modules under action by multiplication from the left, and therefore any left ideal is automatically a submodule. For modules, we fix a conventional left or right action, and focus explicitly on that. \n",
    "\n",
    "A set $B\\subset A$ is said to be a subalgebra of $A$ if in addition to being a submodule, $(B,+)$ is a subspace of $(A,+)$ over the field $F$.\n",
    "\n",
    "A module $W$ is said to be simple if its only submodules are $0=\\{0_W \\}$ and itself. An algebra $A$ (or ring R) is simple if its only left ideals are 0 and itself.\n",
    "\n",
    "We say that $V$ is semisimple if it decomposes into a direct sum of simple submodules. We say that $A$ is semisimple if every $A$ module is semisimple. It turns out that $A$ is semisimple if and only if $A$ as an $A$ module is semisimple. \n",
    "\n",
    "## Algebra, Ring, and Group Representations\n",
    "\n",
    "Let $R$ be a unital ring and $V$ a vector space over a field $F$. We say a representation of a ring $R$ is an F-linear, unital homomorphism $\\rho:R\\rightarrow \\text{End}(V)$. satisfying:\n",
    "\n",
    "1. $\\rho(a+b)=\\rho(a)+\\rho(b)$ for all $a,b\\in R$ (Additive-Homomorphism)\n",
    "2. $\\rho(a\\cdot b)=\\rho(a)\\circ \\rho (b)$ for all $a,b\\in R$ (Multiplicative-Homomorphism)\n",
    "3. $\\rho(1_R)=\\text{id}_{V}$ (Identity-Preserving)\n",
    "\n",
    "For an algebra $A$, in order for $\\rho:A\\rightarrow \\text{End}(V)$ to be an algebra representation it would have to satisfy:\n",
    "\n",
    "1. $\\rho(\\alpha a+\\beta b)=\\alpha\\rho(a)+\\beta\\rho(b)$ for all $a,b\\in A$, $\\alpha,\\beta\\in F$ (Linearity)\n",
    "2. $\\rho(\\alpha a\\cdot b)=\\alpha \\rho(a)\\circ \\rho (b)$ for all $a,b\\in A$, $\\alpha\\in F$ (Multiplicative-Homomorphism)\n",
    "3. $\\rho(1_A)=\\text{id}_{V}$ (Identity-Preserving)\n",
    "\n",
    "It wouldn't make much sense to have the vector space and the algebra to be over different fields, unless $A$'s field is a subfield of $V$'s. But for our purposes we will just work with examples where they are over the same field.\n",
    "\n",
    "For a group $G$, we say that $\\rho:G\\rightarrow \\text{End}(V)$ is a group representation if \n",
    "\n",
    "1. $\\rho(a\\cdot b)=\\rho(a)\\circ \\rho (b)$ for all $a,b\\in G$ (Multiplicative-Homomorphism)\n",
    "2. $\\rho(1_G)=\\text{id}_{V}$ (Identity-Preserving)\n",
    "\n",
    "Representations are useful tools in understanding rings as endomorphism rings of vector spaces. With these definitions, any vector space inherits a structure as a left $R$ module by defining the action as $r\\cdot v=\\rho(r)(v)$. It also means that we may rely on linear algebra tools to solve certain problems. We usually refer to a representation as the ordered pair $(\\rho,V)$.\n",
    "\n",
    "Let $\\rho$ be an algebra representation of $A$. We say $(\\pi,W)$ is a subrepresentation of $(\\rho,V)$ if $W$ is a subspace of $V$, and for all $a\\in A$ we have that $\\pi(a)=\\rho(a)\\vert_{W}$, i.e. the action of $A$ preserves $W$. In that sense $W$ is just a submodule of $V$ as $A$ modules.\n",
    "\n",
    "A representation is said to be irreducible (or simple) if its only subrepresentations are itself and the trivial subrepresentation, where the subspace consists of only the zero vector. With these definitions it is easy to see that the irreducible representations of a ring are equivalent to the simple submodules of vector spaces. And therefore, the full decomposition of a space according to the action of algebra is isomorphic to the decomposition of the representation as the direct sum of irreducible representations.\n",
    "\n",
    "For example, let $G=S_2=\\{1,(1~2) \\}$ be the set of permutations of $\\{1,2\\}$ and $F=\\mathbb{C}$. Then $FG$ is a two-dimensional algebra. The standard representation sends\n",
    "\n",
    "$$1\\mapsto \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}, (1~2)\\mapsto \\begin{pmatrix}0 & 1 \\\\ 1 & 0\\end{pmatrix}$$\n",
    "\n",
    "with ordered basis $(1,(1~2))$. As a module, this decomposition is $\\mathbb{C}\\{1+(1~2)\\}\\oplus\\mathbb{C}\\{1 -(1~2)\\}=\\mathbb{C}\\{v_1\\}\\oplus\\mathbb{C}\\{v_2\\}$, and so $\\rho=\\rho_+\\oplus\\rho_-$, where $\\rho_+((1~2))v_1=v_1$, and $\\rho_-((1~2))v_2=-v_2$. With this new basis,\n",
    "\n",
    "$$ 1\\mapsto 1\\oplus 1,~(1~2)\\mapsto 1\\oplus (-1)$$\n",
    "\n",
    "The gist is then in order to understand an $A$ module, it is best to understand the set of irreducible representations, or simple $A$ modules $\\{A^\\lambda \\}$, where $A^\\lambda$ is a summand of the semisimple decomposition of $A$. If $M$ is an A-module, then we define $M^\\lambda=\\bigoplus_{A^\\lambda \\cong U\\subset M} U\\cong \\bigoplus_{i=1}^{m_\\lambda} A^\\lambda=m_\\lambda A^\\lambda$, i.e. the sum of distinct submodules isomorphic to $A^\\lambda$. $m_\\lambda$ is the multiplicity of the of $A^\\lambda$ in $M$.\n",
    "\n",
    "An important tool in the characterization of simple submodules is given by the trace form of the representation $(\\rho,V)$. If $\\rho=\\rho_{\\lambda_1}\\oplus...\\oplus\\rho_{\\lambda_n}$ is a semisimple decomposition of the representation acting on the semisimple decomposition $V=V^{\\lambda_1}\\oplus...\\oplus V^{\\lambda_n}$, we define the character of a representation $\\rho_{\\lambda_k}$ to be $\\chi_{\\lambda_k}:A\\rightarrow F$, where $\\chi_{\\lambda_k}(a)=\\text{tr}(\\rho_{\\lambda_k}(a))$.\n",
    "\n",
    "## Lie Algebras and Lie Algebra Representations\n",
    "\n",
    "A Lie algebra is a bit of a misnomer as it is not an algebra at all. A Lie algebra is a vector space, $\\mathfrak{g}$, over a field equipped with a bilinear Lie bracket $[\\cdot,\\cdot]:\\mathfrak{g}\\otimes\\mathfrak{g}\\rightarrow\\mathfrak{g}$ such that:\n",
    "\n",
    "1. $[x,y]=-[y,x]$ (Skew-symmetric)\n",
    "2. $[x,[y,z]]+[y,[z,x]]+[z,[y,x]]$=0 (Jacobi Identity)\n",
    "\n",
    "A common example is $\\mathbb{R}^3$ in which the Lie bracket is the cross product of two vectors.\n",
    "\n",
    "A Lie Algebra representation is a map $\\rho:\\mathfrak{g}\\rightarrow \\text{End}(V)$ such that for all $x,y\\in \\mathfrak{g}$ and $\\alpha,\\beta\\in F$:\n",
    "\n",
    "1. $\\rho(\\alpha x+\\beta y)=\\alpha\\rho(x)+\\beta \\rho(y)$ (F-linearity)\n",
    "2. $\\rho([x,y])=\\rho(x)\\rho(y)-\\rho(y)\\rho(x)$ (Commutator Under Bracket)\n",
    "\n",
    "While a Lie algebra is not an algebra, its universal enveloping algebra, $U_\\mathfrak{g}$ is. The universal enveloping algebra of a Lie algebra is the (often infinite dimensional) free algebra over $F$ generated by the basis elements of $\\mathfrak{g}$, say $x_1,x_2,...$ with additional relations. If $[x_i,x_j]=\\sum_k c_k^{i,j}x_k$ in the Lie algebra, then the relations in $U_\\mathfrak{g}$ are given as $x_ix_j-x_jx_i=\\sum_k c_k^{i,j}x_k$. In essence it encodes every possible representation of a Lie algebra. This means that a representation of a Lie algebra can be extended to its universal enveloping algebra, and the two representations are equivalent and admit the exact same decompositions of spaces.\n",
    "\n",
    "## A Taste of Lie Methods\n",
    "\n",
    "An important consequence is that $(xy)\\cdot v= ([x,y]+yx)\\cdot v$ for any $x,y\\in U_\\mathfrak{g}$. This identity is extremely useful in the study of Lie algebras. For example if $[x,y]=h$ and $v$ is an eigenvector of $h$, with eigenvalue $\\lambda$ and we know that $x\\cdot v=0$ then $x\\cdot (y\\cdot v)=(\\lambda + 0)v=\\lambda v$, and we see that $(y\\cdot v)\\mapsto \\lambda v$ under the action of $x$. This is useful in what is known as a highest-weight decomposition by the element $h$. If $V$ is a complex vector space, there must exist one eigenvector $v^{+}$ for which $h v^{+}=\\mu v^{+}$, assuming $h\\neq 0$. Since $V$ is finite-dimensional, there is some $k>0$ for which $x^{k+1} v=0$, but $x^k v = v \\neq 0$ as long as $h(x^k)v^{+}=\\mu_k$, for distinct $\\mu_k$. This ensures that each $x^kv^+$ isn't a scalar multiple of another. Therefore, this $v$ exists. Working backwards, let $h\\cdot v=\\lambda v$, and show that the eigenvalues of $\\{v,yv,y^2v,...,y^{d}v\\}$ under $h$ are all distinct, and $y^{d+1}v=0$. Then $\\{v,yv,y^2v,...,y^{d}v\\}$ forms a d+1 dimensional subspace, called $L(d)$. If $x$ sends $y^{k}v$ to a scalar multiple of $y^{k-1}v$ for all $k=1,...,d$, (and v to 0) then we know that $L(d)$ is an $\\mathbb{C}\\{x,y,h\\}$-invariant subspace, or simple submodule, of $V$. The triple $(x,y,h)$ is called an $\\mathfrak{sl}_2$ triple, and $h$ is what is known as a Cartan element for $x$ and $y$. \n",
    "\n",
    "## Connections Between Lie Groups and Lie Algebras\n",
    "\n",
    "A Lie algebra is naturally associated to a Lie group, $G$, as long as $G$ is both a group and a smooth (real or complex) manifold (a manifold whose charts to $\\mathbb{R}$ or $\\mathbb{C}$ and transition functions are $C^\\infty$) and the left action $G\\times G\\rightarrow G$ defined as $(a,b)\\mapsto a^{-1}b$ is a smooth map from the product manifold to $G$. A Lie algebra is then the (complex or real) vector space $T_1 G$, the tangent space of $G$ at the identity element $1\\in G$. For example, the quotient space $\\mathbb{R}/\\mathbb{Z}\\cong S^1$ is a real Lie group, and its associated Lie algebra is isomorphic to $\\mathbb{R}$. \n",
    "\n",
    "## Some More Examples\n",
    "\n",
    "The complex Lie group of $2\\times 2$ determinant one matrices with complex entries, $SL_2(\\mathbb{C})$ has the Lie algebra $\\mathfrak{sl}_2(\\mathbb{C})$ of the $\\mathbb{C}$ linear span of traceless complex matrices. It has a canonical basis as $\\mathbb{C}$ vector space $\\{x,y,h\\}$, with $x=\\begin{pmatrix}0 & 1 \\\\ 0 & 0\\end{pmatrix}$, $y=\\begin{pmatrix}0 & 0\\\\ 1 & 0\\end{pmatrix}$, $h=\\begin{pmatrix}1 & 0\\\\ 0 & -1\\end{pmatrix}$. Moreover, $[x,y]=xy-yx$ is the commutator Lie bracket. The $\\mathfrak{sl}_2$ triple that we mentioned earlier here is $(x,y,h)$. In general, $\\mathfrak{sl}_n(\\mathbb{C})$ is the $\\mathbb{C}$ span of traceless $n\\times n$ complex matrices.\n",
    "\n",
    "For the group $SL_2(\\mathbb{R})$, the basis is the same, except $\\mathfrak{sl}_2(\\mathbb{R})$ is the $\\mathbb{R}$ span of those matrices.\n",
    "\n",
    "We define the complexification of a real Lie algebra, $\\mathfrak{g}$ as the vector space $\\mathfrak{g}_\\mathbb{C}=\\mathbb{C}\\otimes_{\\mathbb{R}} \\mathfrak{g}$. It is no coincidence that the complexification of $\\mathfrak{sl}_2(\\mathbb{R})$ is $\\mathfrak{sl}_2(\\mathbb{C})$. It is true that the complex representations of the  complexification of real Lie algebra are equivalent to the complex representations of that real Lie algebra.\n",
    "\n",
    "However, it is true that the representation of a simply connected Lie group $G$ is equivalent to its Lie algebra representation. Lie algebras are therefore important tools in studying how various vector spaces decompose under the action of a Lie group. Moreover, many Lie groups are not finitely generated, e.g. $S^1$. As finite-dimensional vector spaces, its Lie algebra as a vector space is considered finitely generated. If $G$ is not simply connected, there are other specific criterias for when the complexified algebra representation is equivalent to the real group representation.\n",
    "\n",
    "For example, let $SO_3(\\mathbb{R})$ be the group of rotation matrices. The complexification of its Lie algebra, $\\mathfrak{so}_3(\\mathbb{R})$ is the $\\mathbb{C}$ span of matrices:\n",
    "\n",
    "$$J_x=\\begin{pmatrix} 0 & 0 & 0\\\\ 0 & 0 & -1\\\\ 0 & 1 & 0 \\end{pmatrix}, J_y=\\begin{pmatrix} 0 & 0 & 1\\\\ 0 & 0 & 0\\\\ -1 & 0 & 0 \\end{pmatrix}, J_z=\\begin{pmatrix} 0 & -1 & 0\\\\ 1 & 0 & 0\\\\ 0 & 0 & 0 \\end{pmatrix} $$\n",
    "\n",
    "denoted $\\mathfrak{so}_3(\\mathbb{C})$. The Lie bracket here is also just the matrix commutator. This Lie algebra is isomorphic to $\\mathfrak{sl}_2(\\mathbb{C})$ by taking $J_x\\mapsto \\frac{1}{2}(x-y)$, $J_y\\mapsto \\frac{i}{2}(x+y)$, and $J_z\\mapsto\\frac{ih}{2}$. A Lie algebra homomorphism is a homomorphism of vector spaces, $\\psi$, such that $\\psi([A,B])=[\\psi(A),\\psi(B)]$ for all $A,B$ and respective Lie brackets. It is an isomorphism if it is an isomorphism of vector spaces. From here on we consider an $\\mathfrak{so}_3(\\mathbb{C})$ representation as a $\\mathfrak{sl}_2(\\mathbb{C})$ representation.\n",
    "\n",
    "We know of a decomposition of invariant subspaces via the highest weigth decomposition using eigenvalues of $\\rho(h)$. One great criteria for checking if a representation of $\\mathfrak{sl}_2(\\mathbb{C})$ lifts to a representation of $SO_3(\\mathbb{R})$ is that it happens when $e^{i\\pi\\rho(h)}=\\text{id}_V$, where $e^A=\\sum_{k=0}^\\infty A^k/k!$ for $A\\in \\text{End}(V)$. So if $V\\cong L(d)= \\mathbb{C}v\\oplus\\mathbb{C}yv\\oplus...\\oplus\\mathbb{C}y^dv$, and $\\rho(h)= \\text{diag}(\\lambda_0,...,\\lambda_d)$ with respect to this basis, we would require that $e^{i\\pi \\lambda_k}=1$ for all $k$, i.e. each $\\lambda_k$ is an even integer, as seen on pg. 83 in Alexander Kirillov's \"An Introduction to Lie Groups and Lie Algebras.\" \n",
    "\n",
    "The connection here is that the exponential function take the Lie algebra of $SO_3(\\mathbb{R})$ to the Lie Group via a parametrization, i.e. $e^{tJ_z}$ maps to the rotation of $\\mathbb{R}^3$ about the $z$-axis by $t$ radians. A Lie algebra representation $\\psi$ is equivalent to its Lie group representation if there exists an $\\Psi:G\\rightarrow GL(V)$ for which $\\Psi(e^X)=e^{\\psi(X)}$ for all $X$ in the Lie algebra.\n",
    "\n",
    "By our isomorphism, this is identical to saying $e^{2\\pi \\psi(J_z)}$ acts trivially on $V$, i.e. the eigenvalues of $\\psi(J_z)$ are all of the form $im$ for $m\\in \\mathbb{Z}$. To prove why this would work, requires us to look at the lifted representation of $\\psi$ onto the simply connected universal cover of $SO_2(\\mathbb{R})$, which is isomorphic to the real special unitary group $SU(2)$. The complexification of its Lie algebra is $\\mathfrak{sl}_2(\\mathbb{C})$, and therefore implies that $SU(2)$'s complex representations are equivalent to $\\mathfrak{sl}_2(\\mathbb{C})$'s complex representations, so there is a representation $\\widetilde{\\Psi}$ on $SU(2)$ that is equivalent to $\\psi$. If one can show that for the covering map $p:SU(2)\\rightarrow SO_3(\\mathbb{R})$, if $\\text{ker}~p\\subset \\text{ker}\\widetilde{\\Psi}$, then $\\widetilde{\\Psi}$ descends to a representation $\\Psi$ on $SO_3(\\mathbb{R})$ for which $\\Psi \\circ p=\\widetilde{\\Psi}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idempotents \n",
    "\n",
    "Another vastly important tool in understanding module decompositions involves the calculation of primitive, central, orthogonal idempotents. Recall an idempotent of a ring, $R$, is an element $e$ for which $e^2=e$. We say that $e$ is:\n",
    "\n",
    "1. Central if $e$ commutes with every element in $R$\n",
    "\n",
    "We say that a collection of distinct idempotents $\\{e_\\lambda\\}$ and $\\lambda\\in\\Lambda$ are:\n",
    "\n",
    "1. Primitive if $\\sum_\\lambda e_\\lambda = 1$, the identity element in $R$\n",
    "2. Orthogonal if for any two $e_\\lambda, e_\\mu$ we have $e_\\lambda e_\\mu =0$ if $\\lambda\\neq \\mu$\n",
    "\n",
    "\n",
    "## Artin-Wedderburn Theorem\n",
    "Let $A$ be a non-trivial, finite-dimensional, unital algebra over a field $F$. Let $M$ be an $A$-module. Then the following are equivalent:\n",
    "\n",
    "1. The left-regular module $A$ admits a full decomposition as $A\\cong\\bigoplus_{\\lambda\\in\\Lambda} A e_\\lambda$, where $\\{e_\\lambda\\}$ are a set of central, primitive, orthogonal idempotents satisfying $\\sum e_\\lambda=1_A$ and $Ae_\\lambda=A^\\lambda$\n",
    "2. $A$ decomposes as the direct sum of endomorphism rings over division rings, i.e. $A\\cong \\bigoplus _{i=1}^{\\ell}M_{n_i\\times n_i}(\\Delta_i)$\n",
    "3. $A$ is semisimple\n",
    "\n",
    "Since $A$ is an algebra, it follows automatically that each $\\Delta_i$ is actually just $F$. The idempotents become important in the study of centralizer algebras because they project the module, say $V$, in question onto a direct sum of isomorphic components $n_\\lambda V_\\lambda$, where $V_\\lambda$ is a representative of the isomorphism class $\\lambda$. Thus, up to a choice of basis, one can identify each idempotent with an element of $\\Lambda$, and $V\\cong\\bigoplus_{\\lambda\\in \\hat{V}}V^\\lambda$, where $V^\\lambda\\cong n_\\lambda Ae_\\lambda$, and $\\lambda \\in \\hat{V}$ satisfies that $V^\\lambda \\neq 0$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Idempotents of Group Algebras\n",
    "\n",
    "Let $FG$ be a finite-dimensional, semisimple group algebra. We define the standard representation $\\rho:FG\\rightarrow \\text{End}(FG)$ by taking the group element to its action on the basis $\\{g~:~g\\in G\\}$ and extending $F$-linearly. Let $\\rho=\\oplus_\\lambda \\rho_\\lambda$ be the semisimple decomposition of $\\rho$. Then the primitive, central, idempotent corresponding to $\\lambda$ is given as:\n",
    "\n",
    "$$ e_\\lambda=\\frac{\\chi_\\lambda(1_G)}{|G|}\\sum_{g\\in G}\\chi_\\lambda(g^{-1})g $$\n",
    "\n",
    "[CITE]\n",
    "\n",
    "Going back to our previous example, with $F=\\mathbb{C}$ and $G=S_2$ we have\n",
    "\n",
    "$$e_+=\\chi_+(1_G)/|G|(\\chi_+(1^{-1})\\cdot 1 + \\chi_+((1~2)^{-1})\\cdot (1~2))=\\frac{1}{2}(1_G+(1~2))$$\n",
    "\n",
    "$$e_-=\\chi_-(1_G)/|G|(\\chi_-(1^{-1})\\cdot 1 + \\chi_-((1~2)^{-1})\\cdot (1~2))=\\frac{1}{2}(1_G-(1~2))$$\n",
    "\n",
    "Note that $e_+$ projects onto the subspace for which $(1~2)$ acts by scaling by 1, and $e_-$ projects onto the subspace for which $(1~2)$ acts by scaling by -1.\n",
    "\n",
    "## Theorem (Double-Centralizer Theorem)\n",
    "\n",
    "Let $M$ be a vector space, and $A\\subseteq \\text{End}(M)$. If the algebra $B$ is semisimple, and $B=\\text{End}_A(M)=\\{\\phi\\in\\text{End}(M)~:~ \\phi(\\psi(m))=\\psi(\\phi(m))~\\forall \\psi\\in A,~\\forall m\\in M \\}$, then $\\text{End}_B(M)=A$ and $M$ has a multiplicity-free complete decomposition:\n",
    "\n",
    "\\begin{align*}\n",
    "M\\cong \\bigoplus_{\\lambda\\in\\Lambda} A^\\lambda \\otimes B^\\lambda\n",
    "\\end{align*}\n",
    "\n",
    "as an $A\\otimes B$-bimodule. Here $B^\\lambda$ are mutually, non-isomorphic, simple $B-modules$, where $\\lambda\\in \\Lambda$, an indexing set for the simple submodules of $B$. The $B^\\lambda$'s are known as isotypic components of $M$.\n",
    "\n",
    "Moreover, $A^\\lambda \\otimes B^\\lambda \\cong m_M(\\lambda) A^\\lambda \\cong \\text{dim}(A^\\lambda) B^\\lambda$ as $A$-modules and $B$-modules, respectively. That is to say that $A^\\lambda \\otimes B^\\lambda$ is isomorphic to a number of copies of isotypic components of $M$ as a $B$-module. Here $m_M(\\lambda)$ is the multiplicity of the submodule $A^\\lambda$ in $M$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposition of one-dimensional ${}_{\\mathbb{C}S_k}(\\mathbb{C}^n)^{\\otimes k}$ isotypic components as an $U_{\\mathfrak{sl}_n}\\otimes \\mathbb{C}S_k$-bimodule\n",
    "\n",
    "\n",
    "\n",
    "Let $V=\\mathbb{C}^n$, and $M=V^{\\otimes k}$. We will verify that ${}_{\\mathbb{C}S_k}M$'s one-dimensional isotypic components, as a $\\mathfrak{g}=U_{\\mathfrak{sl_n(\\mathbb{C})}}$-module with the diagonal action on simple tensors: $g\\cdot (v_1\\oplus...\\oplus v_k)=gv_1\\oplus ...\\oplus v_k +...+ v_1\\oplus ... \\oplus gv_k$ decomposes according to the Double-Centralizer Theorem. It is thanks to a theorem of Schur that we know $\\text{End}_{\\mathfrak{g}}(M)=\\mathbb{C}S_k$, where $S_k$ acts on the simple tensors of $M$ by permutation of their orders. And so to understand a decomposition of $M$ under the action of the Lie algebra, it suffices to study its decomposition as a $\\mathbb{C}S_k$ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find a representation $\\rho:S=S_k\\rightarrow \\text{End(M)}$ as it permutes the basis vectos of $M$ before extending it linearly to the group algebra. But first, we need to adopt some kind of convention for the basis vectors of $M$. \n",
    "\n",
    "Let $V$ be the $\\mathbb{C}$-span of standard basis vectors $\\{e_0,...,e_{n-1}\\}$ Let $u_{\\sum_{j=1}^{k}i_j}=e_{i_1}\\otimes...\\otimes e_{i_k}$, with $i_j\\in \\{0,...,n-1\\}$. This gives a bijective relationship between the $n^k$ basis vectors, and the set $\\{0,...,n-1 \\}^k$, i.e. the base n representation of the indexing set for $U=\\{u_j\\}$.\n",
    "\n",
    "An element $\\sigma\\in S_k$ acts on a basis element in $U$ by $\\sigma \\cdot e_{i_1}\\otimes...\\otimes e_{i_k}=e_{i_{\\sigma(1)}}\\otimes...\\otimes e_{i_{\\sigma(k)}}$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If k=3 and n=2, then $(1~2)\\cdot u_5= (1~2)\\cdot e_1\\otimes e_0\\otimes e_1=e_0\\otimes e_1\\otimes e_1=u_3$. For the generators of $S_3$, we have:\n",
    "\n",
    "\\begin{align*}\n",
    "&(1~2)\\mapsto\\left(\\begin{array}{rrrrrrrr}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{array}\\right)\\\\\n",
    "&(1~3)\\mapsto\\left(\\begin{array}{rrrrrrrr}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\n",
    "\\end{array}\\right)\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create a function that takes an element in $S_k$ to its element in $\\text{End}(M)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho(g,n,k):\n",
    "    \"\"\"\n",
    "    function takes an element g in S_k and returns \n",
    "    an n^k x n^k matrix as it acts on basis vectors of M\n",
    "    \"\"\"\n",
    "    z=zero_matrix(n^k)\n",
    "    for j in range(0,n^k):\n",
    "        l=NN(j).digits(n) #list of base n digits\n",
    "        s=[0] # digits returns the minimal list of non-zero elements \n",
    "        #in the expansion, so we need to make it uniform:\n",
    "        while len((n^k-1).digits(n))-len(l) !=0:\n",
    "            l=l+s \n",
    "        l.reverse() # makes list left-justified, i.e.\n",
    "        #3 in base 2 is now [1,1,0]\n",
    "        perm=\"(\"+str(j)+\",\"\n",
    "        m=g(l) # permutes list\n",
    "        m.reverse() # makes list friendly for conversion to base 10\n",
    "        y=0\n",
    "        for i in range(len(l)):\n",
    "            y+=m[i]*n^i # converts to base 10\n",
    "        perm+=str(y)+\")\"        \n",
    "        for i in range(0,n^k): # goes along column, assigns 1 \n",
    "            #if it hits the target basis vector\n",
    "            if i==y:\n",
    "                z[i,j]=1\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm that $(1~2)$ is indeed sent to its matrix in $\\text{End}(M)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0]\n",
      "[0 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0]\n",
      "[0 0 0 0 0 1 0 0]\n",
      "[0 0 1 0 0 0 0 0]\n",
      "[0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 1 0]\n",
      "[0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "n=2\n",
    "k=3\n",
    "S_k=SymmetricGroup(k)\n",
    "g=S_k(\"(1,2)\")\n",
    "print rho(g,n,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding The Irreducible 1-Dimensional Sub-Modules\n",
    "\n",
    "We know that because $\\mathbb{C}S_k$ is semi-simple, so are any $\\mathbb{C}S_k$-modules. The following function will return a list of the one-dimensional simple sub-modules of $M$. It works by a simultaneous eigenspace decomposition of every element in the matrix group $\\rho(S_k)$. First it evaluates the spectrum of eigenvalues in the group, and then it finds the intersection of eigenspaces for every element with respect to a single eigenvalue. When it is done, it stores that space in a list of common eigenspaces of $\\rho(S_k)$. This process repeats until the spectrum is exhausted. This spectrum must be finite, as $\\rho(S_k)$ is finite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_dimensional_simple_sub_modules(n,k):\n",
    "    S_k=SymmetricGroup(k)\n",
    "    R=QQbar\n",
    "    matrix_list=[]\n",
    "    for g in S_k.gens():\n",
    "        matrix_list.append(rho(g,n,k))\n",
    "    G=MatrixGroup(matrix_list)\n",
    "    eigenspectrum=[]\n",
    "    for i in range(0,G.cardinality()):\n",
    "        l= matrix(R,G[i]).eigenvalues()\n",
    "        for j in range(0, n^k):\n",
    "            if l[j] not in eigenspectrum:\n",
    "                eigenspectrum.append(l[j])\n",
    "    common_eigenspace_list=[]\n",
    "    iden=identity_matrix(R,n^k).column_space()\n",
    "    for i in eigenspectrum:\n",
    "        common_eigenspace=iden\n",
    "        mat_eig_space=iden\n",
    "        for j in range(0,G.cardinality()):\n",
    "            mat = matrix(R,G[j])\n",
    "            mat_eig_space=iden\n",
    "            for d in range(0,len(mat.eigenspaces_right())):\n",
    "                if mat.eigenspaces_right()[d][0]==i:\n",
    "                    mat_eig_space=mat.eigenspaces_right()[d][1]\n",
    "            common_eigenspace=common_eigenspace.intersection(mat_eig_space)\n",
    "        if common_eigenspace.dimension() != 0:\n",
    "            common_eigenspace_list.append([i,common_eigenspace])\n",
    "    return common_eigenspace_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will look at the case where $n=2$ and $k=3$. As we can see there are only 4 copies of the trivial $S_3$ module. The first entry is the eigenvalue, and the second is information about the eigenspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, Vector space of degree 8 and dimension 4 over Algebraic Field\n",
      "Basis matrix:\n",
      "[1 0 0 0 0 0 0 0]\n",
      "[0 1 1 0 1 0 0 0]\n",
      "[0 0 0 1 0 1 1 0]\n",
      "[0 0 0 0 0 0 0 1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in one_dimensional_simple_sub_modules(2,3):\n",
    "    print i\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, by duality, the corresponding $\\mathfrak{g}$-module is 4 dimensional and appears with multiplicity 1. The eigenspaces are all one-dimensional.\n",
    "\n",
    "Now if n=k=3, there are both trivial and sign sub-modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, Vector space of degree 27 and dimension 1 over Algebraic Field\n",
      "Basis matrix:\n",
      "[ 0  0  0  0  0  1  0 -1  0  0  0 -1  0  0  0  1  0  0  0  1  0 -1  0  0  0  0  0]]\n",
      "\n",
      "\n",
      "[1, Vector space of degree 27 and dimension 10 over Algebraic Field\n",
      "Basis matrix:\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in one_dimensional_simple_sub_modules(3,3):\n",
    "    print i\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the theorem, corresponding $\\mathfrak{g}$ submodules are 1 dimensional (dual with signed submodule) and 10 dimensional (dual with trivial module)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, finding the one-dimensional submodules really comes down to calculating the simultaneous eigenspaces for each eigenvalue for the endomporphisms in $\\rho(S_k)$, and intersecting them, but we should strive to solve for the higher-dimensional simple sub-modules as well. This only gives us information on the $\\mathfrak{g}$-modules that appear with multiplicity one. Unfortunately, this is the best we can hope for in terms of canonical methods without having to rely on combinatorics and Lie methods.\n",
    "\n",
    "So what can we do? Let us consider the Artin-Wedderburn Theorem as it applies to algebras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $(V,\\rho)$ is an $A$ representation, then $V$ becomes an $A$ module through $\\rho$, and $\\rho(e_\\lambda)$ is the projection of $V$ onto $V^\\lambda$. In this context, these idempotents hold the key to understanding how a space decomposes as an $A$ module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of group algebras, there is a nice formula for calculating idempotents using the elements of the group as standard basis vectors, but it requires that you already understand what the isomorphism classes of the algebra already look like. But in order to generalize for large families of algebras like $\\mathbb{C} S_k$, we need to employ some different tactics. We explore some of these methods later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 8.6",
   "language": "",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
